\subsection{Konzepte}
\label{subsec_Konzepte}
Mit Hilfe der Literaturrecherche konnten weitere Konzepte gefunden werden, welche im Forschungsgebiet des ML im Kontext der Transparenz definiert wurden. 

\subsubsection{Transparentes ML}
\label{subsubsec_TML}
\cite{zhou20182d} nennen das Konzept des transparenten maschinellen Lernens. Dies wird definiert als ML, welches es Nutzern ermöglicht die Entscheidungen des Algorithmus zu verstehen. Mit \textit{Nutzer} beziehen sich die Autoren insbesondere  auf solche Personen, welche nicht über Kenntnisse im Bereich des Trainieren von ML oder Mathematik verfügen. Transparentes ML bedingt mehrere positive Aspekte. Zum einen ermöglicht es Nutzern bessere Entscheidungen zu treffen und es wird sichtbar, ob ein System so funktioniert wie gewünscht. Im besten Falle ließen sich somit sogar Fehler und deren Ursachen aufdecken, was zu besseren Algorithmen führt. \textit{Besser} meint hier nicht im mathematischen Sinne optimiert, sondern den Einsatz von ML in der realen Welt. Des Weiteren stärkt tansparentes ML das Vertrauen. 

\subsubsection{Mensch und Maschine} 
Viele Autoren nennen die Zusammenarbeit von Mensch und Maschine als potenzielle Möglichkeit mehr Transparenz zu schaffen. Grundsätzlich lässt sich durch stärkere Intergation des Menschens in die gesamte ML-Pipeline mehr Transaprenz schaffen 
\cite{zhou20182d}.
Für die Zusammenarbeit von Mensch und Maschine existieren unterschiedliche Konzepte, das am meisten genannte heißt Human-in-the-Loop.
\todo[inline]{ Hier kommt noch eine Human-in-the-Loop Deinfition}
Neben den Vorteilen für Nutzer und Entwickler ergeben sich durch Human-in-the-Loop weitere positive Aspekte. Nach \cite{tam2016analysis} haben menschliche Inspektionen und Eingriffe in einen Klassifikationsalgorithmus im Vergleich zu einem traditionellen Algorithmus zu einer höheren Genauigkeit geführt.

\cite{wenskovitch2021beyond} erwähnt \emph{Human-Machine-Teams} als weitere Möglichkeit Transparenz zu schaffen. Hier arbeiten Menschen und Maschinen auf eine Art und Weise zusammen, in der die Maschine neue Muster erlernt und Menschen aufgrund dessen in der Lage sind neue Forschungsfragen und -hyptothesen zu bilden. Hierbei ist eine visuelle Schnittstelle essenziell für die Kommunikation vgl. Kapitel \todo[inline]{hier Referenz zu Vialsierungskapitel}. 
Auch \cite{westin2020building} weisen auf die Chance für Transparenz durch Human-Machine-Teams hin. Als weiterführende Literatur nennen sie hier z.B. das Modell für Human-Machine-Teams nach \cite{lyons2013being}, welches sich auf gemeinsame Absichten von Mensch und Maschine konzentriert. Weiter nennen sie noch \cite{chen2014situation}, welche das SAT(\emph{situation awareness-based agent transparency})-Modell entwickelt haben, bei dem das Bewusstsein für konkrete Situationen weiter in den Fokus gerückt wird.

\subsubsection{Mentale Modelle}
Im Rahmen der Literaturrecherche konnte herausgestellt werden, dass mentale Modelle, welche sich Nutzer über den Algorithmus bilden, wichtig für das Verständnis sind.
Ein mentales Modell besitzt nach \cite{kulesza2013too} unterschiedliche Ausprägungsformen, so kann zwischen dem strukturellen und dem funktionalen mentalen Modell unterschieden werden. Bildet sich eine Person ein strukturelles mentales Modell, gewinnt sie Erkenntnisse über die Funktionsweise eines Systems. Ein funktionales mentales Modell, hilft Menschen dabei ein System zu nutzen, während ein Verständnis über das System nicht notwendig ist.

\subsubsection{Facetten der Transparenz} 
\cite{vaughan2020human} stellen unterschiedliche Bausteine heraus, aus denen sich Transparenz zusammensetzt. So sei Traceability (dt.: Rückverfolgbarkeit) ein Teil von Transparenz, welcher die Dokumentation der gesteckten Ziele, die angewendeten Definitionen sowie das Systemdesign und die während der Entwicklung getroffenen Annahmen mit einschließt. Des Weiteren spielt die Kommunikation über den Zweck aber auch die Grenzen der AI eine große Rolle. Als dritten Baustein nennen sie Intelligibility (dt.: Verständlichkeit), welche Verständnis und Überwachung für Beteiligte ermöglichen soll. Um Verständlichkeit zu erreichen, spielen XAI-Methoden eine wesentliche Rolle.

\cite{huvc2021anomaly} fächern Transparenz anders auf und gliedern Transparenz in zwei Unteraspekte. Zum einen gibt es die funktionale Transparenz, welche beschreibt, wie ein Algorithmus funktioniert, und des Weiteren die Transparenz in Bezug auf die genutzten Daten.

Eine weitere Facette von Transparenz wurde von \cite{shin2020algorithm} herausgestellt. So beantworte Transparenz eher die Fragen, ob Daten legitimiert genutzt wurden und gibt weniger Auskunft darüber, ob der Algorithmus gut geeignet ist oder im mathematischen Sinne optimiert wurde.

\cite{siau2018building}Transparenz und Erklärbarkeit wirken sich positiv auf Vertrauen aus. \todo[inline]{Dieser Satz ist noch etwas einsam, vlt. solche Aspekte rauswerfen}