\subsection{Weitere Methoden}
\todo[inline]{Wenn das in Ordnung ist, würde ich hier noch einige Methoden auf hoher Abstraktionsebene beschreiben. Es gibt halt sehr viele, und ich glaube nicht dass ich jede (und schon gar nicht zu genau) beschreibene sollt. In der folgenden Auflistung siehst du ein paar von den Methoden, welche mir theoretisch fehlen würde, auch wenn dies nicht alle sind, die ich insgesamt gefunden habe.}
\begin{itemize}
    \item CAM with global average pooling (Sonderformen: Grad-CAM, Guided Grad-CAM mit Feature Occlusion, Repsond CAM, Multi Layer CAM)
    \item DeepLIFT
    \item Prediction Difference Analysis 
    \item Slot Activation Vectors
    \item PRM (Peak Response Mapping)
    \item direct output labels
    \item Image Corruption and Testing Region of interest
    \item Attention map with autofocus convolutional layer
    \item DecnovNet
    \item SVD
    \item CCA
    \item SVCCA
    \item DWT
    \item Explanation Vector
    \item LSTMVis
\end{itemize}

\todo[inline]{Die Methoden könnten dann so oder so ähnlich beschrieben werden}
\textbf{PCA}
\begin{addmargin}[25pt]{0pt}
Principal Component Analysis wurde von \cite{pearson1901liii} eingeführt. und kann zur Feature Extraktion genutzt werden \cite{tjoa2020survey}. Hier wird weniger ein Modell erklärt, als dass die Dimensionen der jeweiligen Merkmale reduziert werden und somit für den Nutzer einfacher verständlich werden. %(https://medium.com/apprentice-journal/pca-application-in-machine-learning-4827c07a61db)
\end{addmargin}
